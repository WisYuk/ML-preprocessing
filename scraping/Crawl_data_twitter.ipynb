{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEWpayxURuUn"
      },
      "source": [
        "# Crawl Data Twitter \n",
        "The crawling process was done using Tweet-Harvest\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6S00x_f6-GeD"
      },
      "outputs": [],
      "source": [
        "#@title Twitter Auth Token\n",
        "\n",
        "twitter_auth_token = 'GG_GEMINK'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4UIL1x21P9rQ",
        "outputId": "94757395-f8c4-4dad-e7fb-f6e6c328fd3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Get:1 https://repo.anaconda.com/pkgs/misc/debrepo/conda stable InRelease [3961 B]\n",
            "Get:2 https://dl.yarnpkg.com/debian stable InRelease [17.1 kB]                 \n",
            "Get:3 https://repo.anaconda.com/pkgs/misc/debrepo/conda stable/main amd64 Packages [4557 B]\n",
            "Get:4 https://dl.yarnpkg.com/debian stable/main all Packages [11.8 kB]         \n",
            "Get:5 https://dl.yarnpkg.com/debian stable/main amd64 Packages [11.8 kB]       \n",
            "Get:6 https://packages.microsoft.com/repos/microsoft-ubuntu-focal-prod focal InRelease [3632 B]\n",
            "Get:7 https://packages.microsoft.com/repos/microsoft-ubuntu-focal-prod focal/main amd64 Packages [293 kB]\n",
            "Get:8 https://packages.microsoft.com/repos/microsoft-ubuntu-focal-prod focal/main all Packages [2714 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]                \n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security InRelease [128 kB]     \n",
            "Get:10 https://packagecloud.io/github/git-lfs/ubuntu focal InRelease [28.0 kB] \n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates InRelease [128 kB]       \n",
            "Get:13 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [29.8 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [3616 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-backports InRelease [128 kB]    \n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]    \n",
            "Get:14 https://packagecloud.io/github/git-lfs/ubuntu focal/main amd64 Packages [3690 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1208 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [3674 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [32.5 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [3766 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [4148 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1504 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\n",
            "Fetched 31.9 MB in 6s (5633 kB/s)                       \n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ca-certificates is already the newest version (20230311ubuntu0.20.04.1).\n",
            "curl is already the newest version (7.68.0-1ubuntu2.22).\n",
            "gnupg is already the newest version (2.2.19-3ubuntu2.2).\n",
            "gnupg set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_20.x nodistro main\n",
            "Hit:1 https://dl.yarnpkg.com/debian stable InRelease\n",
            "Hit:2 https://repo.anaconda.com/pkgs/misc/debrepo/conda stable InRelease       \n",
            "Get:3 https://packages.microsoft.com/repos/microsoft-ubuntu-focal-prod focal InRelease [3632 B]\n",
            "Get:4 https://deb.nodesource.com/node_20.x nodistro InRelease [12.1 kB]        \n",
            "Get:5 https://deb.nodesource.com/node_20.x nodistro/main amd64 Packages [7495 B]\n",
            "Hit:6 http://security.ubuntu.com/ubuntu focal-security InRelease               \n",
            "Hit:7 http://archive.ubuntu.com/ubuntu focal InRelease                         \n",
            "Hit:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease        \n",
            "Hit:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease              \n",
            "Hit:9 https://packagecloud.io/github/git-lfs/ubuntu focal InRelease            \n",
            "Fetched 23.3 kB in 2s (14.3 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 31.6 MB of archives.\n",
            "After this operation, 196 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_20.x nodistro/main amd64 nodejs amd64 20.14.0-1nodesource1 [31.6 MB]\n",
            "Fetched 31.6 MB in 0s (78.8 MB/s)\n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 69958 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_20.14.0-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (20.14.0-1nodesource1) ...\n",
            "Setting up nodejs (20.14.0-1nodesource1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "v20.13.1\n"
          ]
        }
      ],
      "source": [
        "# Import required Python package\n",
        "!pip install pandas\n",
        "\n",
        "# Install Node.js (because tweet-harvest built using Node.js)\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y ca-certificates curl gnupg\n",
        "!sudo mkdir -p /etc/apt/keyrings\n",
        "!curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg\n",
        "\n",
        "!NODE_MAJOR=20 && echo \"deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main\" | sudo tee /etc/apt/sources.list.d/nodesource.list\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install nodejs -y\n",
        "\n",
        "!node -v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLaVT3x-Ksc6",
        "outputId": "dc720002-8a0e-4d2b-c4a2-51dfe7d72849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "removed 2 packages, and changed 63 packages in 4s\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K24 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install -g npm@10.8.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!curl -L -o 'data tourism.xlsx' \"https://docs.google.com/spreadsheets/d/1ealGhVIkeDGOoAGTbsml_SHqjIQaie_x2sssE8k1ISM/export?format=xlsx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = 'data tourism.xlsx'\n",
        "df_T = pd.read_excel(file_path, sheet_name=\"tourism_with_id\")\n",
        "df_T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tgl = [\n",
        "    \"2023-06-01\",\n",
        "    # \"2023-07-01\",\n",
        "    \"2023-08-01\",\n",
        "    # \"2023-09-01\",\n",
        "    \"2023-10-01\",\n",
        "    # \"2023-11-01\",\n",
        "    \"2023-12-01\",\n",
        "    # \"2024-01-01\",\n",
        "    \"2024-02-01\",\n",
        "    # \"2024-03-01\",\n",
        "    \"2024-04-01\",\n",
        "    # \"2024-05-01\",\n",
        "    \"2024-06-01\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crawl Data\n",
        "import glob\n",
        "import os\n",
        "dir = 'tweets-data'\n",
        "def crawl_data(place_id, judul):\n",
        "  raw = judul\n",
        "  parts = raw.split('(')\n",
        "  tempat_wisata = parts[0].strip()\n",
        "  if len(parts) > 1:\n",
        "      AKA = parts[1].rstrip(')')\n",
        "  temp=tempat_wisata\n",
        "  temp = temp.replace(\" \",\"_\")\n",
        "  for i in range(len(tgl)-1):\n",
        "    filename = '{}_{}.csv'.format(temp,i)\n",
        "    src= AKA if len(parts) > 1 else tempat_wisata\n",
        "    search_keyword = '{} since:{} until:{} lang:id Min_faves:1'.format(src,tgl[i],tgl[i+1])\n",
        "    limit = 5\n",
        "    print(search_keyword)\n",
        "    !npx -y tweet-harvest@2.6.1 -o \"{filename}\" -s \"{search_keyword}\" -l {limit} --token {twitter_auth_token}\n",
        "  dfs = []\n",
        "  # print(temp)\n",
        "  csv_files = glob.glob(os.path.join(dir,'{}*.csv'.format(temp)))\n",
        "  # print(csv_files)\n",
        "  for file in csv_files:\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        dfs.append(df)\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(f\"File {file} is empty and will be skipped.\")\n",
        "    finally:\n",
        "        os.remove(file)\n",
        "  if dfs:\n",
        "    merged_df=pd.concat(dfs,ignore_index=True)\n",
        "    merged_df=merged_df[['created_at','favorite_count','full_text','quote_count','reply_count','retweet_count']]\n",
        "    merged_df.to_csv('{}_{}.csv'.format(place_id,temp),index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "first = 5\n",
        "last = 6\n",
        "for i in range(first,last+1):\n",
        "  rows = df_T[df_T['Place_Id'] == i]\n",
        "  for index, row in rows.iterrows():\n",
        "      crawl_data(i,row['Place_Name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "csv_files = glob.glob('*.csv')\n",
        "zip_filename = '{}_{}.zip'.format(first,last)\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    for file in csv_files:\n",
        "        zipf.write(file)\n",
        "        os.remove(file)\n",
        "files.download(zip_filename)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
